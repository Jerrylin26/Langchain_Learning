from langchain.prompts import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
    ChatMessagePromptTemplate
)
from langchain_core.messages.base import BaseMessage
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
import os

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

# SystemMessagePromptTemplate & HumanMessagePromptTemplate
messages = [
    SystemMessagePromptTemplate.from_template('ä½ çš„åå­—æ˜¯{name}'),
    HumanMessagePromptTemplate.from_template('ä½ å«ä»€éº¼åå­—')
]

prompt_tpl =ChatPromptTemplate(
    messages,
    input_variables=['name']
)

print('ğŸŒŠ', prompt_tpl)

# ChatMessagePromptTemplate
messages = [
    ChatMessagePromptTemplate.from_template('ä½ çš„åå­—æ˜¯{name},è«‹æ ¹æ“šè‡ªå·±çš„å§“åå›ç­”å•é¡Œ',role='system'),
    ChatMessagePromptTemplate.from_template('ä½ å«ä»€éº¼åå­—',role='human')
]

prompt_tpl =ChatPromptTemplate(
    messages,
    input_variables=['name']
)

print('ğŸŒŠ', prompt_tpl)


# ChatPromptTemplateæ–¹æ³•
messages = [
    ('system', 'ä½ çš„åå­—æ˜¯{name}ï¼Œè«‹è¨˜ä½ï¼Œå›ç­”æ™‚è¦èªªã€Œæˆ‘å«{name}ã€ã€‚'),
    ('human', 'ä½ å«ä»€éº¼åå­—')
]

prompt_tpl =ChatPromptTemplate.from_messages(
    messages=messages,

)
print('ğŸŒŠ', prompt_tpl)

# .format_messages: list[BaseMessage] 
# .format: BaseMessage
prompt: list[BaseMessage] = prompt_tpl.format_messages(name='é˜¿æ˜')
print('ğŸŒŠ', prompt)

llm = ChatOpenAI(temperature=0.3, api_key=api_key,max_completion_tokens=50)
print('ğŸ¤—', repr(llm.invoke(prompt)))

print('ğŸ¤—', llm.invoke(prompt))

print('ğŸ§­', prompt_tpl.format_prompt(name='é˜¿æ˜'))
print(type(prompt_tpl.format_prompt(name='é˜¿æ˜')))
print('ğŸ§­', prompt_tpl.format_messages(name='é˜¿æ˜'))
print(type(prompt_tpl.format_messages(name='é˜¿æ˜')))
print('ğŸ§­', prompt_tpl.format_prompt(name='é˜¿æ˜').to_string())